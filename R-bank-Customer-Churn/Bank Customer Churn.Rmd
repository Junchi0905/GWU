---
title: "Project 2"
author: "Bravo"
date: "12/11/2018"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r}
library(ResourceSelection)
library(pROC)
library(pscl)
library(ISLR)
library(dplyr)
library(ROCR)
library(bestglm)
library(openintro)
library(leaps)
library(tidyr)
library(plyr)
library(rpart)
library(rpart.plot)

library(car)


```

Import the data
```{r}
bank <- read.csv('Churn_Modelling.csv')
attach(bank)
#The first 3 colomns is not important:RowNumber,CustomerId,SurnameN
bank=bank[,c(-1,-2,-3)]
```

Divide the data set into test and train
```{r}
#We are going to go with a 80% train 20% test appoarch. Not that the common and space tells R to include the entire data.frame
train <- bank[1:8000, ]
test <- bank[8001:10000, ]
```

Subsetting 
forward selection to search
```{r}
reg.forward <- regsubsets(Exited~., data = train, nvmax = 10, nbest = 1, method = "forward")
summary(reg.forward)
plot(reg.forward, scale = "adjr2", main = "Adjusted R^2")
reg.forward
#from the plot, we would like to select CreditScore, Geography, Gender, Age, Balance, IsActiveMember


```

Exploratary Data Analysis
```{r}
#About the whole data
head(bank)
tail(bank, 6)
str(bank)

#About the dependent variable
table(Exited)
str(Exited)

#Overview of all the variables
summary(bank)

#boxplot of the variables
#age
box_age<- boxplot(Age)
#balance
box_balance <- boxplot(Balance)
#credit score
box_creditscore<-boxplot(CreditScore)

#hist of the numeric variable
#Geography
factor_Geography <- as.integer(Geography)
#1 is France, 2 is Germany, 3 is Spain
hist(factor_Geography)

#IsActiveMember
hist(IsActiveMember)

#Age
hist(Age)
```

run logistic regression model, start by using CreditScore, Geography, Gender, Age, Balance, IsActiveMember
```{r}
bank_log<-glm(Exited~CreditScore+Geography+Gender+Age+Balance+IsActiveMember, family = binomial(link = "logit"), data = train)

#Multicollinearity
vif(bank_log)
VIF(bank_log)

summary(bank_log)
#For every one unit change in creditscore, log odds of exited decreases by 5.973e-04
#For every one unit change in age, log odds of exited increases by 7.545e-02
#For every one unit change in balance, log odds of exited increases by 2.999e-06
#For rank uses France as a baseline so log odds increase by 7.333e-01 when moving from France to Germany
#For rank uses Female as a baseline so log odds decrease by 5.780e-01 when moving from Female to Male
#Residual Deviance: Reductions from 8135.0 to 6832.4, not great
#AIC: Akaike information criterion â€“ Comparison between models, lower AIC is better


#Converting log odds coefficients to probabilities via exp() function
bank_log_ouput <- exp(coef(bank_log))
bank_log_ouput
#For every unit increase in credit score the odds of being exited increase by a factor of 0.99940291 or the odds are 1 percent higher (subtract 1 and * 100).
#For every unit increase in age the odds of being exited increase by a factor of 1.078 or the odds are 7 percent higher (subtract 1 and * 100).
#For every unit increase in balance the odds of being exited increase by a factor of 1.0 or the odds are 0 percent higher (subtract 1 and * 100).

#Test our models goodness of fit 
hoslem.test(train$Exited, fitted(bank_log))
#how well your data fits the model. Specifically, the HL test calculates if the observed event rates match the expected event rates in population subgroups.
#p-value is 0.0986, above .05 better

#First we want to use the data to predict the likelihood that each customer will be exited
prob <- plogis(predict(bank_log, type = c("response")))
head(prob)
bank_roc <- roc(Exited~prob,data=train)
plot(bank_roc)
plot(h)#Look good
#Receiver Operating Characteristic: Measure of the Sensitivity (true positive) and Specificity (false positives) of the Model
#Look good

pR2(bank_log)

```

Use the model to predict Exited on the data
```{r}
predict.model2 <- predict.glm(bank_log,test,type='response')
head(predict.model2)

predict.model2.1 <- ifelse(predict.model2 > 0.5,1,0)

#essentially we are creating percentage likelihood of Exited for each value, above 50% we are saying it's more likely to occur.
head(predict.model2.1)

test %>% group_by(Exited) %>% summarise(no_rows = length(Exited))
#So we only had to correctly identify 390 Yes factors, which is 19.5%  of the total factor, not very small
```

hit rate
```{r}
model3hit <- mean(predict.model2.1!=test$Exited)
model3hit#the higher the better
```

Do a roc curve, just to confirm our model, using a different package then our first example
```{r}
#In order to use the package we first have to set the prediction 
newpredict <- prediction(predict.model2,test$Exited)
#Next we want to measure true possitives which is "tpr" and also False Positives "fpr"
newpredict.performance <- performance(newpredict, measure = "tpr",x.measure = "fpr")
#then we plot these two measures
plot(newpredict.performance)
```

get the AUC again using the performance function
```{r}
AUC <- performance(newpredict, measure = "auc")
AUC
```

Use this model to actually predict something
```{r}
actual <- data.frame(CreditScore=650,Geography='France',Gender='Male',Age=38,Balance=76486,IsActiveMember=0)
actualpredict <- predict(bank_log,actual,type='response')
actualpredict
#Likelihood dropped to 16.98%

#prediction about creditscore
new.data.test1 <- data.frame(CreditScore=350:850,Geography='France',Gender='Male',Age=38,Balance=76486,IsActiveMember=0)
new.data.test.pred1 <- predict(bank_log,new.data.test1, type = "response")
head(new.data.test.pred1)
scatter.smooth(new.data.test.pred1, xlab = "CreditScore", ylab = "Likelihood of Exited")

#prediction about Geography
new.data.test2 <- data.frame(CreditScore=650,Geography=rep(c('France','France','Spain'),2),Gender='Male',Age=38,Balance=76486,IsActiveMember=0)
new.data.test.pred2 <- predict(bank_log,new.data.test2, type = "response")
head(new.data.test.pred2)
scatter.smooth(new.data.test.pred2, xlab = "Geography", ylab = "Likelihood of Exited")

#prediction about Gender
new.data.test3 <- data.frame(CreditScore=650,Geography='France',Gender=c('Male','Female'),Age=38,Balance=76486,IsActiveMember=0)
new.data.test.pred3 <- predict(bank_log,new.data.test3, type = "response")
head(new.data.test.pred3)
scatter.smooth(new.data.test.pred3, xlab = "Gender", ylab = "Likelihood of Exited")

#prediction about Age
new.data.test4 <- data.frame(CreditScore=650,Geography='France',Gender='Male',Age=18:92,Balance=76486,IsActiveMember=0)
new.data.test.pred4 <- predict(bank_log,new.data.test4, type = "response")
head(new.data.test.pred4)
scatter.smooth(new.data.test.pred4, xlab = "Age", ylab = "Likelihood of Exited")

#prediction about Balance
new.data.test5 <- data.frame(CreditScore=650,Geography='France',Gender='Male',Age=38,Balance=0:250898,IsActiveMember=0)
new.data.test.pred5 <- predict(bank_log,new.data.test5, type = "response")
head(new.data.test.pred5)
scatter.smooth(new.data.test.pred5, xlab = "Balance", ylab = "Likelihood of Exited")

#prediction about IsActiveMember
new.data.test6 <- data.frame(CreditScore=650,Geography='France',Gender='Male',Age=38,Balance=76486,IsActiveMember=as.integer(0:1))
new.data.test.pred6 <- predict(bank_log,new.data.test6, type = "response")
head(new.data.test.pred6)
scatter.smooth(new.data.test.pred6, xlab = "IsActiveMember", ylab = "Likelihood of Exited")

```





Use another model: Decision Tree to build
```{r}
str(bank)

#Build the model
# Train the tree with the rpart() function.
# We'll need to set the seed to make the results reproducible. 
set.seed(1)
bank_tree_gini = rpart(Exited~.,                    
                            method = "class",	             
                            data = bank)      
rpart.plot(bank_tree_gini)
``` 

```{r}
# Let's use the "predict" function to test our our model and then 
# evaluate the accuracy of the results.
bank_model = predict(bank_tree_gini, type = "class")

# Let's compare the results to the actual data.
bank_matrix = table(bank_model, train$Exited)
bank_matrix

table(bank_model)

# The error rate is defined as a classification of "Pregnant" when 
# this is not the case, and vice versa. It's the sum of all the
# values where a column contains the opposite value of the row.
sum(bank_matrix[row(bank_matrix) != col(bank_matrix)])
# 1118


# The error rate divides this figure by the total number of data points
# for which the forecast is created.
sum(bank_matrix)
# 8000

# Let's use these values in 1 calculation.
bank_error_rate = sum(bank_matrix[row(bank_matrix) != col(bank_matrix)]) / 
                  sum(bank_matrix)


paste0("Real error rate is: ", bank_error_rate * 100, "%")
# "Real error rate is: 13.975%"
```

```{r}
bank_model<- as.numeric(bank_model)

predict.model2.1 <- ifelse(bank_model > 0.5,1,0)
#essentially we are creating percentage likelihood of Exited for each value, above 50% we are saying it's more likely to occur.
head(predict.model2.1)

model4hit <- mean(predict.model2.1!=test$Exited)
model4hit
#80.5%, absolutely higher than the one on logsitic regression.
```

